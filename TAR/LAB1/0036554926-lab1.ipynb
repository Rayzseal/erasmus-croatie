{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77230ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3a318fbf027eed5ee48e1c6d83e9891",
     "grade": false,
     "grade_id": "cell-cbdf7d65ea58446b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "University of Zagreb\\\n",
    "Faculty of Electrical Engineering and Computing\n",
    "\n",
    "## Text Analysis and Retrieval 2022/2023\n",
    "https://www.fer.unizg.hr/predmet/apt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee22e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2a1ed35ddafecf28cc99b0b8ef28dc3",
     "grade": false,
     "grade_id": "cell-5e9c1e104dec0dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------------------------------\n",
    "\n",
    "### Basics of NLP\n",
    "\n",
    "*Version: 1.2*\n",
    "\n",
    "(c) 2022 Josip Jukić, Jan Šnajder\n",
    "\n",
    "Submission deadline: **March 26, 2023, 23:59 CET** \n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333437b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94b9faebe9a09cb0c30acb0ddccd3275",
     "grade": false,
     "grade_id": "cell-b25d76fa7c847af2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Hello visitor, this lab assignment consists of three parts. Your task boils down to filling out the missing parts of the code and evaluating the cells. These parts are indicated by the \"YOUR CODE HERE\" template.\n",
    "\n",
    "Each subtask is supplemented by several tests that you can run. Apart from that, there are some additional tests that will be executed after submission. If your solution is valid and passes all visible tests, there shouldn't be any problems with the additional tests. Some of the tests depend on certain versions of Python packages (provided within the instructions), so we advise you to use the identical versions. However, this is optional since the evaluation will be conducted on an isolated machine with matching versions. Just keep in mind that some tests can fail even though your solution is correct if you use different package versions (this won't affect your final grading).\n",
    "\n",
    "**IMPORTANT: Don't change the names of the predefined methods or random seeds** because the tests won't be executed properly. \n",
    "\n",
    "You're required to do this assignment **on your own**.\n",
    "\n",
    "If you stumble upon problems, please refer to josip.jukic@fer.hr for office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f31b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd1654b2c7c8de8e1d1cfaeeee261ec2",
     "grade": false,
     "grade_id": "cell-150c23ae802b9522",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503faa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0398d566c69a62089f0eb60546d6340d",
     "grade": false,
     "grade_id": "cell-95afad8333fec3bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d3b8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b155864b06eca3cc7daa9d3c05433e43",
     "grade": false,
     "grade_id": "cell-6eb6dc1bc414cf1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will use [spaCy](https://spacy.io/) exetensively in this assigment. You are advised to study the main aspects of this tool. You can go through the basics [here](https://spacy.io/usage/spacy-101). We recommend that you go through the procedures that we covered in the lectures: tokenization, lemmatization, part-of-speech (POS) tagging, and named entity recognition (NER).\n",
    "\n",
    "Furthermore, we will rely on [NumPy](https://numpy.org/) and [pandas](https://pandas.pydata.org/) libraries. If you are not familiar with those libraries, we advise you to go through [this tutorial](https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49891d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d800562",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18574758fbae85b229fb5ad20ca9cdda",
     "grade": false,
     "grade_id": "cell-16202be1385f6781",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "Process the example below with spaCy. Tokenize the document and gather the tokens in a list. Finally, print the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d34e4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f9573e9524d0566357ec211312ce57",
     "grade": false,
     "grade_id": "cell-8fa80d1ece04d737",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex1_a1 = (\n",
    "    \"A wizard is never late, Frodo Baggins. \"\n",
    "    \"Nor is he early; he arrives precisely when he means to.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bfdd25",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eece1ba6d97bcb94ee0a4e5ae7499ac0",
     "grade": false,
     "grade_id": "cell-10252e22a675688e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "wizard\n",
      "is\n",
      "never\n",
      "late\n",
      ",\n",
      "Frodo\n",
      "Baggins\n",
      ".\n",
      "Nor\n",
      "is\n",
      "he\n",
      "early\n",
      ";\n",
      "he\n",
      "arrives\n",
      "precisely\n",
      "when\n",
      "he\n",
      "means\n",
      "to\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(ex1_a1)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a8590",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbc65ec903d48d3665d4227c2343f2bc",
     "grade": false,
     "grade_id": "cell-bb0718d5e7f50e40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "Implement `sentencizer` using [spaCy](https://spacy.io/usage/linguistic-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8da2f50",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "640f18a880a339d3a99335a3a8164771",
     "grade": false,
     "grade_id": "cell-f24e1081f2af60b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sentencizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input,\n",
    "    splits the document to sentences and gathers them in a list.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    mylist = []\n",
    "    for phrases in doc.sents:\n",
    "       mylist.append(phrases.text)\n",
    "    \n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39e0309",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7998a7e3d2e527b89800c50bdca72ba7",
     "grade": true,
     "grade_id": "cell-cda5936073984160",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sentencizer(\"Sentence no. 1. Sentence no. 2.\") == [\n",
    "    \"Sentence no. 1.\",\n",
    "    \"Sentence no. 2.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab61006",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dada93ac32be275cfea235c17f9ba0f4",
     "grade": false,
     "grade_id": "cell-a39ece84bbd22997",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "\n",
    "Implement `lemmatizer` using [spaCy](https://spacy.io/usage/linguistic-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462c67dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e0bc45a957906ca13e967ab5e083fbc",
     "grade": false,
     "grade_id": "cell-759698a86a73114f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    The lemmas are returned in a list.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    mylist = []\n",
    "    for tokens in doc: \n",
    "       mylist.append(tokens.lemma_)\n",
    "    \n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cad45e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28b18c2fc2b5c5c6020c81abcd5f7f26",
     "grade": true,
     "grade_id": "cell-1381a0323dde41cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert lemmatizer(ex1_a1) == [\n",
    "    \"a\",\n",
    "    \"wizard\",\n",
    "    \"be\",\n",
    "    \"never\",\n",
    "    \"late\",\n",
    "    \",\",\n",
    "    \"Frodo\",\n",
    "    \"Baggins\",\n",
    "    \".\",\n",
    "    \"nor\",\n",
    "    \"be\",\n",
    "    \"he\",\n",
    "    \"early\",\n",
    "    \";\",\n",
    "    \"he\",\n",
    "    \"arrive\",\n",
    "    \"precisely\",\n",
    "    \"when\",\n",
    "    \"he\",\n",
    "    \"mean\",\n",
    "    \"to\",\n",
    "    \".\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccb113",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "300d915802e7c3337f5d6fcd3ede3ed3",
     "grade": false,
     "grade_id": "cell-a20b39684be6b375",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (d)\n",
    "\n",
    "Implement the `ngrams` methods. You might find the [`tee`](https://www.geeksforgeeks.org/python-itertools-tee/) method from the `itertools` package useful, but you're not obliged to use it. The method should return a generator. Plase refer to the [link](https://wiki.python.org/moin/Generators) if you aren't familiar with Python generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06186b52",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cc9b2358491234483fce15870678054",
     "grade": false,
     "grade_id": "cell-66b11d5510c3d6ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "\n",
    "\n",
    "def ngrams(sequence, n, **kwargs):\n",
    "    \"\"\"\n",
    "    Receives a list of tokens and generates n-grams.\n",
    "    \"\"\"\n",
    "    return [tuple(sequence[y] for y in range(i,i+n)) for i in range (0,len(sequence) - n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72da564",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0b5586930150617ae69345587517487",
     "grade": true,
     "grade_id": "cell-01b516b6b34b5d58",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert list(ngrams(lemmatizer(ex1_a1), 2)) == [\n",
    "    (\"a\", \"wizard\"),\n",
    "    (\"wizard\", \"be\"),\n",
    "    (\"be\", \"never\"),\n",
    "    (\"never\", \"late\"),\n",
    "    (\"late\", \",\"),\n",
    "    (\",\", \"Frodo\"),\n",
    "    (\"Frodo\", \"Baggins\"),\n",
    "    (\"Baggins\", \".\"),\n",
    "    (\".\", \"nor\"),\n",
    "    (\"nor\", \"be\"),\n",
    "    (\"be\", \"he\"),\n",
    "    (\"he\", \"early\"),\n",
    "    (\"early\", \";\"),\n",
    "    (\";\", \"he\"),\n",
    "    (\"he\", \"arrive\"),\n",
    "    (\"arrive\", \"precisely\"),\n",
    "    (\"precisely\", \"when\"),\n",
    "    (\"when\", \"he\"),\n",
    "    (\"he\", \"mean\"),\n",
    "    (\"mean\", \"to\"),\n",
    "    (\"to\", \".\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0feaf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "805632bc6f160ec920cb46d8ac316635",
     "grade": false,
     "grade_id": "cell-adf3d7b2e18c3c03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. News classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ebb3c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5710b4dd093696b8a707c458df74ad3d",
     "grade": false,
     "grade_id": "cell-878dc37f021783b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "Load the prepared BBC news data to a `pandas` dataframe named `df_bbc`. Explore the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93bc621a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db8a261fbf823db01013aaade4756761",
     "grade": false,
     "grade_id": "cell-46a1f24f0267c57e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_bbc = pd.read_csv('bbc.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a03e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a0d78cfdf34a6e2cedc984f1a7d6b24",
     "grade": false,
     "grade_id": "cell-6953e1e113497d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "To make the classification task a bit more challenging, we want to remove the news title from the text.\\\n",
    "Additionally, we will replace all whitespaces with single spaces. Implement title removal and whitespace replacement in `clean_text`.\\\n",
    "E.g., \"This \\n is  \\t an &nbsp;&nbsp;&nbsp;&nbsp; example. \" -> \"This is an example.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a13f8b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64739bab014639562d3c2be4139a6ada",
     "grade": false,
     "grade_id": "cell-51a7b044e7fb5900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes news title and replaces all whitespaces with single spaces.\n",
    "    Returns preprocessed text.\n",
    "    \"\"\"\n",
    "    \n",
    "    texts = text.split(\"\\n\")\n",
    "    del texts[0]\n",
    "    noDSpace =  \" \".join(texts)\n",
    "    noDSpace = \" \".join(noDSpace.split())\n",
    "    return noDSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d7cc6d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f669133bd4f9965634a4003e0fa4fbe2",
     "grade": true,
     "grade_id": "cell-fce2e38e985bdf90",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (\n",
    "    clean_text(\"Breaking news\\nClever Hans \\t learns  to integrate.\")\n",
    "    == \"Clever Hans learns to integrate.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04359889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbc[\"text\"] = df_bbc.news.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dde023",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5b797a92e500947361d27d951dad1f2",
     "grade": false,
     "grade_id": "cell-1608d0dfbb292ba4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "(1) Implement an abstract pipeline in `preprocess_pipe`. The method receieves a sequence of texts and a pipe function, which is used to preprocess documents in combination with the spaCy model `nlp` that we loaded at the beggining. We recommend you to use [`pipe`](https://spacy.io/usage/processing-pipelines).\\\n",
    "(2) Implement `lemmatize_pipe` that collects lemmas and returns a list of n-grams ranging from `ngram_min` to `ngram_max`. Additonally, **truncate** the documents to `max_len` tokens and **remove the stop words**. Refer to the tests below to see how this method should behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a8d5c10",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "871d62e1e2fecb7c68afcc50a4a1c15d",
     "grade": false,
     "grade_id": "cell-d767fae648cfcd8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc, max_len, ngram_min, ngram_max):\n",
    "    \"\"\"\n",
    "    Removes stopword, truncates the document to `max_len` tokens,\n",
    "    and returns lemma n-grams in range [`ngram_min`, `ngram_max`].\n",
    "    \"\"\"\n",
    "    \n",
    "    clean = [token for token in doc if not token.is_stop]\n",
    "        \n",
    "    if (len(clean) >= max_len):\n",
    "        for i in range(len(clean)-1,max_len, -1):\n",
    "            del clean[i]\n",
    "        \n",
    "    lemmas = []\n",
    "    \n",
    "    for lemma in clean:\n",
    "        lemmas.append(lemma.lemma_)\n",
    "    \n",
    "    mylist = []\n",
    "    \n",
    "    for i in range(ngram_min,ngram_max + 1):\n",
    "        mylist += (ngrams(lemmas,i))\n",
    "        \n",
    "    return mylist\n",
    "    \n",
    "\n",
    "\n",
    "def preprocess_pipe(texts, pipe_fn):\n",
    "    pipelist = []\n",
    "    for t in texts:\n",
    "        pipelist.append(pipe_fn(nlp(t)))\n",
    "    return pipelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fa0dc4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaaf424e75df3ace41f83b75cca082e4",
     "grade": true,
     "grade_id": "cell-17c77fd435574993",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "pipe_fn = partial(lemmatize_pipe, max_len=100, ngram_min=1, ngram_max=2)\n",
    "\n",
    "ex2_c1 = [\"Text no. 1\", \"Text no. 2\"]\n",
    "sol2_c1 = [\n",
    "    [(\"text\",), (\".\",), (\"1\",), (\"text\", \".\"), (\".\", \"1\")],\n",
    "    [(\"text\",), (\".\",), (\"2\",), (\"text\", \".\"), (\".\", \"2\")],\n",
    "]\n",
    "\n",
    "assert preprocess_pipe(ex2_c1, pipe_fn) == sol2_c1\n",
    "\n",
    "ex2_c2 = [\n",
    "    \"It’s a dangerous business, Frodo, going out your door.\",\n",
    "    \"You step onto the road, and if you don’t keep your feet, there’s no knowing where you might be swept off to.\",\n",
    "]\n",
    "sol2_c2 = [\n",
    "    [\n",
    "        (\"dangerous\",),\n",
    "        (\"business\",),\n",
    "        (\",\",),\n",
    "        (\"Frodo\",),\n",
    "        (\",\",),\n",
    "        (\"go\",),\n",
    "        (\"door\",),\n",
    "        (\".\",),\n",
    "        (\"dangerous\", \"business\"),\n",
    "        (\"business\", \",\"),\n",
    "        (\",\", \"Frodo\"),\n",
    "        (\"Frodo\", \",\"),\n",
    "        (\",\", \"go\"),\n",
    "        (\"go\", \"door\"),\n",
    "        (\"door\", \".\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"step\",),\n",
    "        (\"road\",),\n",
    "        (\",\",),\n",
    "        (\"foot\",),\n",
    "        (\",\",),\n",
    "        (\"know\",),\n",
    "        (\"sweep\",),\n",
    "        (\".\",),\n",
    "        (\"step\", \"road\"),\n",
    "        (\"road\", \",\"),\n",
    "        (\",\", \"foot\"),\n",
    "        (\"foot\", \",\"),\n",
    "        (\",\", \"know\"),\n",
    "        (\"know\", \"sweep\"),\n",
    "        (\"sweep\", \".\"),\n",
    "    ],\n",
    "]\n",
    "\n",
    "assert preprocess_pipe(ex2_c2, pipe_fn) == sol2_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e927475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pipe_fn = partial(lemmatize_pipe, max_len=100, ngram_min=1, ngram_max=2)\n",
    "df_bbc[\"lemmas\"] = preprocess_pipe(df_bbc.text, pipe_fn)\n",
    "df_bbc_train, df_bbc_test = train_test_split(\n",
    "    df_bbc[[\"lemmas\", \"type\"]], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41262657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Load vectorizers\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16506e26",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4510ffeba73a0e3705161c9b7165cbb3",
     "grade": false,
     "grade_id": "cell-47236b49a9e757a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (d)\n",
    "Implement `train_lr`. Run `test_performance` with count and TF-IDF vectorizer. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "02d032e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba851ee17994c47b71e16eb24c255e91",
     "grade": false,
     "grade_id": "cell-3ffaa74fc8341360",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "\n",
    "def train_lr(df_train, vectorizer, lr_kwargs={\"max_iter\": 1000, \"solver\": \"lbfgs\"}):\n",
    "    \"\"\"\n",
    "    Receives the train set `df_train` as pd.DataFrame and extracts lemma n-grams\n",
    "    with their correspoding labels (news type).\n",
    "    The text is vectorized and used to train a logistic regression with\n",
    "    training arguments passed as `lr_kwargs`.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    X = vectorizer.fit_transform(df_train['lemmas'])\n",
    "    clf = LR(**lr_kwargs).fit(X,df_train['type'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "aaa13b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def test_performance(model, df_test, vectorizer):\n",
    "    X_test, y_test = df_test.lemmas, df_test.type\n",
    "    X_vec = vectorizer.transform(X_test)\n",
    "    y_pred = model.predict(X_vec)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fffebe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85d7002a20bc26808eb96c9c519748cb",
     "grade": true,
     "grade_id": "cell-b4268c290c91d4c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c1a933bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.91      0.91      0.91        11\n",
      "entertainment       0.83      0.83      0.83         6\n",
      "     politics       1.00      0.88      0.93         8\n",
      "        sport       0.92      1.00      0.96        12\n",
      "         tech       0.67      0.67      0.67         3\n",
      "\n",
      "     accuracy                           0.90        40\n",
      "    macro avg       0.87      0.86      0.86        40\n",
      " weighted avg       0.90      0.90      0.90        40\n",
      "\n",
      "f1 = 0.860\n"
     ]
    }
   ],
   "source": [
    "## Count vectorizer scenario\n",
    "lr = train_lr(df_bbc_train, count_vectorizer)\n",
    "f1 = test_performance(lr, df_bbc_test, count_vectorizer)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3ef13b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.79      1.00      0.88        11\n",
      "entertainment       1.00      0.67      0.80         6\n",
      "     politics       1.00      0.88      0.93         8\n",
      "        sport       0.92      1.00      0.96        12\n",
      "         tech       1.00      0.67      0.80         3\n",
      "\n",
      "     accuracy                           0.90        40\n",
      "    macro avg       0.94      0.84      0.87        40\n",
      " weighted avg       0.92      0.90      0.90        40\n",
      "\n",
      "f1 = 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## TF-IDF vectorizer scenario\n",
    "lr = train_lr(df_bbc_train, tfidf_vectorizer)\n",
    "f1 = test_performance(lr, df_bbc_test, tfidf_vectorizer)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64facf03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8a06faba4c2671cea9b86ac44af94bc",
     "grade": false,
     "grade_id": "cell-98ecce1759dc6e45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3. Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ff418",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3aa1fafcc0fbc9387081f4f2b007094",
     "grade": false,
     "grade_id": "cell-97c49c613d446926",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Named entity recognition (NER) is a NLP that seeks to classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, quantities, monetary values, percentages, etc. Refer to [Jurafsky \\& Martin, Speech and Language Processing, Chapter 17](https://web.stanford.edu/~jurafsky/slp3/17.pdf) for additional information.\n",
    "\n",
    "In this task, we will try out two approaches:\n",
    "1. **classification**, where we classify named entities for each word in a document,\n",
    "2. and **sequence labeling**, a more natural way to solve NER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d891e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "281a9dc52d61b9345eaa67026b457c75",
     "grade": false,
     "grade_id": "cell-5a71afb947371882",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's see spaCy's visualization tool `displacy` in action. We will take the first document from our data frame and render named entities with spaCy's default NER model. Although there are some minor innacuracies, spaCy's NER model generally performs very well (~90% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae0ebf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">New 'yob' targets to be unveiled</br> </br> \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fifty\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " new areas getting special help to fight anti-social behaviour in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wales\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " will be named on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br> </br> \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ten\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " areas have already had access to special prosecutors and local experts and the government is now expanding the crackdown to more towns and cities. Details of how many anti-social behaviour orders (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asbos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ") were used in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " are also being published. Labour sees nuisance behaviour as a key election issue but critics claim the record is at best patchy. \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A year ago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", ministers launched their anti-social behaviour plan and \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "'s figures offer a progress check. They will say that in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the past year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 2,600\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " anti-social behaviour orders were issued by the courts - more than double the total used in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the previous four years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br> </br> Police have also closed \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    150\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " crack houses and issued \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 400\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " dispersal orders, breaking up groups of youths in public places. The \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " new pilot areas to get special attention will also receive extra government funding. Exeter and Cardiff are among cities who have voiced interest in being involved.</br> </br> Prime Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tony Blair\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is also expected to announce new measures to strengthen the use of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asbos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and fixed penalty notices. There are still concerns that some areas of the country are not using the powers properly.</br> </br> He is expected to say that the new figures were heartening but he would not rest until similar action was taken in all areas of the country where it was needed. &quot;We have not defeated this problem by any means, but shown together what can be done,&quot; he will say. Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Blair\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " defended the shake-up of the licensing laws, saying it was right to focus on troublemakers rather than treating everybody as a potential drunken nuisance.</br> </br> Ministers also boast of record police numbers and are speeding up plans to put in place \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    25,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " community support officers (CSOs). But researchers from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Leeds University\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " warned that CSOs could undermine traditional bonds between police officers and communities. More work needed to be done on clarifying the role of different agencies and how they linked together before CSOs, they argued in a the study. Critics of the government say it has announced \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 20\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " initiatives to tackle nuisance behaviour when the real focus should be on good policing. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Home Office\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hazel Blears\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " also revealed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " that &quot;\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about a third\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "&quot; of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asbos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " were breached - with some people jailed and others not.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "\n",
    "doc = nlp(df_bbc.news.iloc[0])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d6da4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e2dd0a3c1938262c74e3b22a5ba6bf6",
     "grade": false,
     "grade_id": "cell-aaf6abd44485d157",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "We want to use spaCy's deafult model to produce silver standard NER labels for our BBC news dataset. First step is to implement `entity_pipe`, a method that extracts POS tags and NER labels, which we will pass as an argument to `preprocess_pipe`. `entity_pipe` receives a spaCy document, extracts triplets in the form of (token, POS tag, named entity label), and returns the list of collected triplets. Refer to [spaCy's documention for NER](https://spacy.io/usage/linguistic-features#named-entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6bf8c6bd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467a7938cfe111e1fc1a8e1c1f2d5f2b",
     "grade": false,
     "grade_id": "cell-fd433993b28d314c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entity_pipe(doc):\n",
    "    res = []\n",
    "    for token in doc:\n",
    "        entval = None\n",
    "        for ent in doc.ents:\n",
    "            entval = ent.label_\n",
    "        if str(token.ent_iob_) == \"B\": # If we use ent_iob : 0 = out; 1 = in; 2 = out; 3 = begin\n",
    "            res += [(token.text, token.tag_, token.ent_iob_ +'-'+entval)]\n",
    "        else:\n",
    "            res += [(token.text, token.tag_, token.ent_iob_)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76b328ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ede27ac8ab161d7a4d486237198c50",
     "grade": true,
     "grade_id": "cell-d6d93f8d56b0d8e9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "ex3_a1 = [\n",
    "    \"One does not simply walk into Mordor.\",\n",
    "    \"What about second breakfast?\",\n",
    "]\n",
    "sol3_a1 = [\n",
    "    [\n",
    "        (\"One\", \"PRP\", \"O\"),\n",
    "        (\"does\", \"VBZ\", \"O\"),\n",
    "        (\"not\", \"RB\", \"O\"),\n",
    "        (\"simply\", \"RB\", \"O\"),\n",
    "        (\"walk\", \"VB\", \"O\"),\n",
    "        (\"into\", \"IN\", \"O\"),\n",
    "        (\"Mordor\", \"NNP\", \"B-ORG\"),\n",
    "        (\".\", \".\", \"O\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"What\", \"WP\", \"O\"),\n",
    "        (\"about\", \"IN\", \"O\"),\n",
    "        (\"second\", \"JJ\", \"B-ORDINAL\"),\n",
    "        (\"breakfast\", \"NN\", \"O\"),\n",
    "        (\"?\", \".\", \"O\"),\n",
    "    ],\n",
    "]\n",
    "assert preprocess_pipe(ex3_a1, entity_pipe) == sol3_a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c69b04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30e959aa7eca996b98a9b41d3b7c8ed8",
     "grade": false,
     "grade_id": "cell-3a37ef269efc526a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will only the first 50 documents to reduce the computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b73af685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>POS</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fifty</td>\n",
       "      <td>CD</td>\n",
       "      <td>B-GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>areas</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>getting</td>\n",
       "      <td>VBG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>special</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  POS    tag\n",
       "0    Fifty   CD  B-GPE\n",
       "1      new   JJ      O\n",
       "2    areas  NNS      O\n",
       "3  getting  VBG      O\n",
       "4  special   JJ      O"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbc_trunc = df_bbc[:50].copy()\n",
    "\n",
    "df_bbc_trunc[\"tags\"] = preprocess_pipe(df_bbc_trunc[\"text\"], entity_pipe)\n",
    "data = sum(df_bbc_trunc[\"tags\"], [])\n",
    "tokens, pos, tags = zip(*data)\n",
    "df_iob = pd.DataFrame({\"token\": tokens, \"POS\": pos, \"tag\": tags})\n",
    "df_iob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e0688",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bde96fc0c7fde0b4f522a516ffe4f6f",
     "grade": false,
     "grade_id": "cell-19cd1a79d82d17df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "Vectorize the data in `df_iob` with [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html). You can transform the datafframe to a dictionary with [`to_dict`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html). The structure of the dictionary should look like so: [{column -> value}, … , {column -> value}]. Refer to the linked documentation to see how to utilize the `orient` argument.\n",
    "After vectorization, split the data using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with `test_size=0.5` and `shuffle=False` to preserve the sentence structure. We are trying to classify named entites, so you can simply use the `tag` column from `df_iob` to extract labels. You can keep them in the string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "parallel-steal",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6458a88505e29243276ccec489156a",
     "grade": false,
     "grade_id": "cell-771cc8409e2ed46c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "toDataFrame = df_iob[['tag']]\n",
    "\n",
    "dictionnary = df_iob.to_dict('records')\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "vector = v.fit_transform(df_iob.to_dict('records'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, df_iob['tag'], test_size = 0.5 ,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cbc36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d24ae3f1d8bd30fa44c91e3d8ab1e1d4",
     "grade": true,
     "grade_id": "cell-08e13487d4b2350c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e4cd71a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c03e28fc594e7eb252c21f09359f647",
     "grade": false,
     "grade_id": "cell-c98f6159909f5178",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can train your classifier now. For this purpose, let's choose Multinomial Naïve Bayes (MNB). Since MNB can learn incrementally, notice that we train our model with [`partial_fit`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.partial_fit) to reduce the computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2755858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-CARDINAL       0.00      0.00      0.00        27\n",
      "      B-DATE       0.82      0.99      0.89       271\n",
      "       B-GPE       1.00      1.00      1.00         2\n",
      "       B-LOC       0.00      0.00      0.00        47\n",
      "     B-MONEY       1.00      0.77      0.87        60\n",
      "      B-NORP       0.00      0.00      0.00         0\n",
      "       B-ORG       1.00      0.99      0.99       351\n",
      "   B-PERCENT       0.00      0.00      0.00        95\n",
      "    B-PERSON       1.00      0.92      0.96       166\n",
      "      B-TIME       0.00      0.00      0.00        33\n",
      "           I       0.87      0.99      0.93       643\n",
      "           O       0.99      1.00      1.00      9379\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     11074\n",
      "   macro avg       0.56      0.55      0.55     11074\n",
      "weighted avg       0.96      0.98      0.97     11074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chloe\\miniconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "classes = np.unique(df_iob.tag.values).tolist()\n",
    "nb = MultinomialNB()\n",
    "nb.partial_fit(X_train, y_train, classes)\n",
    "\n",
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d70f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b83eda178738178a222ccf87517f3a6",
     "grade": false,
     "grade_id": "cell-94382553ba8f8926",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For non-sparse classes, the $F_1$ score should be close to $1$. The possible explanation is that spaCy's default NER model is rule-based, which makes it easy to learn. Remeber that we used spaCy to produce silver labels. To check how the classifier performs on human-annotated data, let's explore the next dataset \"ner.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8f8946f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\")\n",
    "# Fill NaNs with preceding values (for the \"Sentence #\" column).\n",
    "df_ner.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfde73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93f9dd003fc8a5d3a8d9026eae8bc509",
     "grade": false,
     "grade_id": "cell-48b614c32d72b784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Repeat the same procedure as in **(b)** with [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) on `df_clf`. Use [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with `test_size=0.5` and `shuffle=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "134e69c4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "429e2dde8d5aa0c8ea218e365a7328f5",
     "grade": false,
     "grade_id": "cell-d4fbdfec3e6fea05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_clf = df_ner[[\"Word\", \"POS\", \"Tag\"]]\n",
    "\n",
    "toDataFrame = df_clf[[\"Tag\"]]\n",
    "\n",
    "dictionnary = df_clf.to_dict('records')\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "vector = v.fit_transform(df_clf.to_dict('records'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, df_clf[\"Tag\"], test_size = 0.5 ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d11f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7146f0e740162ab6e6b5b57716c882",
     "grade": true,
     "grade_id": "cell-8a44880e7fc3e9e7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020728d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6228462e25a98da19836f785fb97fb1a",
     "grade": false,
     "grade_id": "cell-9bbd26c2859cd0a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's drop the `O` tag, since it is the most frequent tag and it is hard to interpret the performance quality when it is included. This will give us a more realistic `F_1` score. If you wish, you can compare the results by setting `labels=classes` instead of `labels=new_classes`. If your classifier performs terribly, that is expected, so don't worry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec86735",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "print(\n",
    "    classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=new_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c05cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15011d0291ec5bb8487cbac04411080d",
     "grade": false,
     "grade_id": "cell-3eec27b54065f6e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's try to improve the performance with the sequence labeling approach. Specifically, we're going to use CRF. First, we have to prepare the sentence-level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "sentences = df_ner.groupby(\"Sentence #\").Word.agg(lambda s: \" \".join(s)).values.tolist()\n",
    "processed = preprocess_pipe(sentences, entity_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452f6a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "220ffd9d5e4b45499b5d5a37bc9d54dd",
     "grade": false,
     "grade_id": "cell-b81b065411cd357a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "Implement missing features in `token2features`:\n",
    "- -1:token.lower() = preceding token in lowercase\n",
    "- -1:token.istitle() = is the preceding token a title\n",
    "- -1:token.isupper() = is the preceding token written in all caps\n",
    "- -1:postag = POS tag of the preceding token\n",
    "\n",
    "Analogously, add the same features for succeeding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197cedf6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1f924372b07f791f8a0ff32da3dc8aa",
     "grade": false,
     "grade_id": "cell-4f8ca4c7a8c34404",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def token2features(sent, i):\n",
    "    token = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"token.lower()\": token.lower(),\n",
    "        \"token[-3:]\": token[-3:],\n",
    "        \"token[-2:]\": token[-2:],\n",
    "        \"token.isupper()\": token.isupper(),\n",
    "        \"token.istitle()\": token.istitle(),\n",
    "        \"token.isdigit()\": token.isdigit(),\n",
    "        \"postag\": postag,\n",
    "        \"postag[:2]\": postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update(\n",
    "            {\n",
    "                \"-1:token.lower()\": sent[i-1][0].lower(),\n",
    "                \"-1:token.istitle()\": sent[i-1][0].istitle(),\n",
    "                \"-1:token.isupper()\": sent[i-1][0].isupper(),\n",
    "                \"-1:postag\": sent[i-1][1],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "    if i < len(sent) - 1:\n",
    "        features.update(\n",
    "            {\n",
    "                \"+1:token.lower()\": sent[i+1][0].lower(),\n",
    "                \"+1:token.istitle()\": sent[i+1][0].istitle(),\n",
    "                \"+1:token.isupper()\": sent[i+1][0].isupper(),\n",
    "                \"+1:postag\": sent[i+1][1],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [token2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for _, _, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, _, _ in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa25a9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae60f5765168b4432b3a0e8fe1b58eee",
     "grade": true,
     "grade_id": "cell-ce2404350ff8e421",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex3_b1 = [\n",
    "    (\"Thousands\", \"NNS\", \"B-CARDINAL\"),\n",
    "    (\"of\", \"IN\", \"O\"),\n",
    "    (\"demonstrators\", \"NNS\", \"O\"),\n",
    "    (\"have\", \"VBP\", \"O\"),\n",
    "    (\"marched\", \"VBN\", \"O\"),\n",
    "    (\"through\", \"IN\", \"O\"),\n",
    "    (\"London\", \"NNP\", \"B-GPE\"),\n",
    "    (\"to\", \"TO\", \"O\"),\n",
    "    (\"protest\", \"VB\", \"O\"),\n",
    "    (\"the\", \"DT\", \"O\"),\n",
    "    (\"war\", \"NN\", \"O\"),\n",
    "    (\"in\", \"IN\", \"O\"),\n",
    "    (\"Iraq\", \"NNP\", \"B-GPE\"),\n",
    "    (\"and\", \"CC\", \"O\"),\n",
    "    (\"demand\", \"VB\", \"O\"),\n",
    "    (\"the\", \"DT\", \"O\"),\n",
    "    (\"withdrawal\", \"NN\", \"O\"),\n",
    "    (\"of\", \"IN\", \"O\"),\n",
    "    (\"British\", \"JJ\", \"B-NORP\"),\n",
    "    (\"troops\", \"NNS\", \"O\"),\n",
    "    (\"from\", \"IN\", \"O\"),\n",
    "    (\"that\", \"DT\", \"O\"),\n",
    "    (\"country\", \"NN\", \"O\"),\n",
    "    (\".\", \".\", \"O\"),\n",
    "]\n",
    "\n",
    "sol3_b1 = {\n",
    "    \"bias\": 1.0,\n",
    "    \"token.lower()\": \"through\",\n",
    "    \"token[-3:]\": \"ugh\",\n",
    "    \"token[-2:]\": \"gh\",\n",
    "    \"token.isupper()\": False,\n",
    "    \"token.istitle()\": False,\n",
    "    \"token.isdigit()\": False,\n",
    "    \"postag\": \"IN\",\n",
    "    \"postag[:2]\": \"IN\",\n",
    "    \"-1:token.lower()\": \"marched\",\n",
    "    \"-1:token.istitle()\": False,\n",
    "    \"-1:token.isupper()\": False,\n",
    "    \"-1:postag\": \"VBN\",\n",
    "    \"+1:token.lower()\": \"london\",\n",
    "    \"+1:token.istitle()\": True,\n",
    "    \"+1:token.isupper()\": False,\n",
    "    \"+1:postag\": \"NNP\",\n",
    "}\n",
    "\n",
    "assert sent2features(ex3_b1)[5] == sol3_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in processed]\n",
    "y = [sent2labels(s) for s in processed]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d0682",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b54f0de35062f6a39c63deb20bd9a77",
     "grade": false,
     "grade_id": "cell-6f8321146de778a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If the training lasts too long, you can reduce `max_iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddbc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075ca4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7260389f3db874b02c88f9258875264",
     "grade": false,
     "grade_id": "cell-5e71552b29527ddc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "CRF should heavily outperform our previous attempt with the classifier. Check the performance without the `O` tag. If you wish, you can see how $F_1$ changes if you include the `O` tag, simply by setting `labels=classes` in `flat_classification_report`. The benefits of solving NER as a sequence labeling task should be obvious after you inspect the margin of improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a074f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baecdf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28e4d706e8b2e88cc70ad6eb97ed47cb",
     "grade": false,
     "grade_id": "cell-101a4c137df7738a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's explore the top (un)likely transitions. Can you spot any expected patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc924d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_trans = 20\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-14s -> %-14s: %0.5f\" % (label_from, label_to, weight))\n",
    "\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(top_n_trans))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-top_n_trans:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362aae9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "678006c1883cea5032550f0a4f5b2c26",
     "grade": false,
     "grade_id": "cell-fd1243cfc20e9ac9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Additionally, let's take a look at the most important features for specific tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_feat = 30\n",
    "\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.5f %-14s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(top_n_feat))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Top negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-top_n_feat:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee17db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e42321e71f2eafb801fc75c13a868d37",
     "grade": false,
     "grade_id": "cell-339eac0c87542c35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's conclude this assignment with an overview of CRF feature importance using the `eli5` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(crf, top=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
